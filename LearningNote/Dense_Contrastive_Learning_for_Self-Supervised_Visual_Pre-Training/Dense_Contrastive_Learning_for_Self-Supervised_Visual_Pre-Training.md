# Dense Contrastive Learning for Self-Supervised Visual Pre-Training

[toc]

- 词短句翻译

  sub-optimal：不是最好的，次佳的

  discrepancy：不符，矛盾

  contrastive：对比的

  negligible：微不足道的

  overhead：费用，支出

  paradigm：范例

  dominant：占优势的

  straightforward：直接的直观的

  notoriously：众所周知地，臭名昭著地，（贬义词）

## Abstract

迄今为止，多数自监督学习方法多针对图片分类领域涉及优化。但是由于图片级别的预测和像素级别的预测的差别，这些预训练模型并不是最优的。为了弥补这一差距（To fill this gap），我们致力于设计一个有效，密集预测的自监督学习方法，根据局部特征之间的对应关系实现像素级别（局部特征）的预测工作。基于上述想法，我们提出了密集对抗学习，通过优化输入图在不同视图之间相对应像素级相似损失（不行四损失），实现了自监督学习。

相较于基准方法MoCo-v2，我们的方法虽然多出了一些微不足道的花销（only <1% slower），但是在迁移到下游任务（downstream task：包括目标检测、语义分割以及实例分割）上时保持了一贯的优秀表现，且比当前最先进的方法提升极大。特别地，与强大的MoCo-v2基线相比，我们的方法取得了显著的改进，在PASCAL VOC目标检测和语义分割，COCO的目标检测和实例分割，Cityscapes语义分割任务上都取得了一定的进步

## Introduction

在许多计算机视觉任务中，预训练已经形成一个标准的流程（a well-established paradigm）。在一个经典的预训练流程中，模型会先在大规模的数据机上进行预训练，然后在较小的训练数据上进行目标任务的精细调整。值得一提的是，受监督的ImageNet预训练多年来一直占据主导地位，它的预训练模型主要为了解决图片分类问题，同时能够迁移到其余下游任务。但是，图片分类和希望能够密集预测的任务，比如目标检测和语义分割，之间有差距。前者专注于对一张输入图片赋予一个标签，而后者需要对整张图片进行密集预测（比如：对像素进行预测）或回归。举例来说，语义分割需要对每一个像素设置标签，目标检测则是对于所有关注实例进行标签预测和物体框的检测。一个直观的解决办法是直接针对密集预测任务进行预训练。然而，这些任务的标注信息相比于图片级别的标签，生成花费过于庞大，因此难以收集到大规模的有标注的数据去进行通用的特征预训练模型。  

近段时间，无监督视觉相关预训练受到了极大研究的关注，旨在从在庞大的无标签数据集中学习到合适的特征（a proper visual representation，合适的预训练模型）。有一些方法已经证明了在下游任务上，得到了不逊色于基于ImageNet数据集监督性预训练模型效果的结果